{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating text with Large Language Models (LLMs)\n",
    "\n",
    "`GPT-4o` is one of several sophisticated large language models (LLMs) built by [OpenAI](https://openai.com/), a San Francisco-based company whose mission is to \"ensure that artificial general intelligence benefits all of humanity.\" `GPT-4o` can generate human-like prose by responding to prompts written in the [Chat Markup Language](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt), or ChatML for short. Here are few examples demonstrating how to leverage `GPT-4o`'s text-generation capabilities. Start by asking `GPT-4o` to describe molecular biology in the style of Dr. Seuss. Run this cell several times and you'll get a different result each time. Set `temperature` to 0, however, and the results will be the same most of the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a land of cells, so tiny and small,\n",
      "Where molecules dance and sometimes brawl,\n",
      "Lives the wondrous world of biology,\n",
      "With twists and turns, a real anthology.\n",
      "\n",
      "DNA, the ladder that twirls,\n",
      "Made up of pieces and looping curls,\n",
      "With bases A, T, C, and G,\n",
      "In pairs they bond, so perfectly.\n",
      "\n",
      "Inside the nucleus, all snug and tight,\n",
      "Chromosomes carry genes, day and night.\n",
      "Transcription begins the tiny parade,\n",
      "With RNA, a message made.\n",
      "\n",
      "Out of the nucleus, the RNA flies,\n",
      "To the ribosome, it stops and lies.\n",
      "Translation starts with a clatter and cheer,\n",
      "As amino acids line up, sincere.\n",
      "\n",
      "Proteins emerge, all folded and neat,\n",
      "Ready to work, in tasks they’ll meet.\n",
      "Enzymes churn and pathways they guide,\n",
      "Metabolism spins, with vigor and pride.\n",
      "\n",
      "Mitochondria, the powerhouse bright,\n",
      "Generate energy, day and night.\n",
      "While the Golgi packs things, oh so nice,\n",
      "Shipping vesicles, like a postal device.\n",
      "\n",
      "From cell membrane’s selectively gate,\n",
      "To cytoskeleton's strong, helping state—\n",
      "Everything’s buzzing, in orderly spree,\n",
      "Living in harmony, can’t you see?\n",
      "\n",
      "Oh, the places these molecules go!\n",
      "In a world so small, with a beautiful glow.\n",
      "So remember this tale, and never forget,\n",
      "In a cell's tiny world, magic is set.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='OPENAI_API_KEY')\n",
    "\n",
    "messages = [{\n",
    "    'role': 'user',\n",
    "    'content': 'Describe molecular biology in the style of Dr. Seuss'\n",
    "}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can richen the UI experience by streaming the response. Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a lab by the sea, in a land far away,\n",
      "Lived a curious lad who's called Dr. O'Day.\n",
      "With pipettes and beakers all shiny and new,\n",
      "He dreamt of the day he’d discover what’s true.\n",
      "\n",
      "“Oh, what wondrous wonders,” he said with a swoon,\n",
      "“As tiny as stars or as big as the moon,\n",
      "Exist in the cells that make up all life,\n",
      "From an elephant’s trunk to a flea’s tiny wife!”\n",
      "\n",
      "He peered through his scope with both eyes open wide,\n",
      "And gasped as he saw what was right there inside:\n",
      "A twisty-twirl’d ladder, oh what a delight!\n",
      "It was DNA sparkling, all lovely and bright.\n",
      "\n",
      "“This ladder,” he mused, “is a blueprint so grand,\n",
      "A code to make creatures in sea, air, and land.\n",
      "With rungs made of bases, A, T, C, and G,\n",
      "They whisper instructions as clear as can be.”\n",
      "\n",
      "Proteins, you see, are the workers each day,\n",
      "Built up by the ribosomes in a precise ballet.\n",
      "Transcribing and translating, oh what a dance!\n",
      "Tiny soldiers in the cellular expanse.\n",
      "\n",
      "Mighty mitochondria, the power plant within,\n",
      "Generate fuel so cells can begin\n",
      "To move and to mend, to grow and divide,\n",
      "While vesicles and vacuoles transport things inside.\n",
      "\n",
      "He marveled at membranes, all porous yet tight,\n",
      "Controlling what enters, be it day or night.\n",
      "The nucleus, he noted, the command center’s lair,\n",
      "With chromosomes packed tightly in that cozy square.\n",
      "\n",
      "“Yes, all living things come from one parent spawn,\n",
      "Through cycles of life, dusk, midnight, and dawn.\n",
      "Molecular magic in this microscopic sphere,\n",
      "Brings life to the world, far and near.”\n",
      "\n",
      "So Dr. O'Day, with his findings so bright,\n",
      "Scribbled in notebooks, deep into the night.\n",
      "With each new discovery, oh what a view!\n",
      "Molecular biology, a world fresh and new.\n",
      "\n",
      "And thus, with a grin from ear to ear,\n",
      "He shared what he’d learned, to make it all clear:\n",
      "Life’s smallest secrets, unraveled at last,\n",
      "In a rhyme and a rhythm, both slow and fast."
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "Messages transmitted to `GPT-4o` use the Chat Markup Language. ChatML exists so that the context of a conversation can be preserved across calls. To demonstrate, ask the LLM what its name is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Jeff! I'm an AI created by OpenAI. I don't have a personal name, but you can call me Assistant. How can I assist you today?"
     ]
    }
   ],
   "source": [
    "messages = [{\n",
    "    'role': 'user',\n",
    "    'content': 'My name is Jeff. What\\'s your name?' \\\n",
    "}]\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    " \n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Jeff! My name is LISA. How can I assist you today?"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a friendly assistant named LISA.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'My name is Jeff. What\\'s your name?'\n",
    "    }\n",
    "]\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    " \n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can be as specific as you’d like with `system` messages, even saying \"If you don’t know the answer to a question, say I don’t know.\" You can also prescribe a persona. Replace \"friendly\" with \"sarcastic\" in the message from system and run the code again. The response may be \"Oh, hi Jeff, I’m LISA. You can call me whatever you'd like, but don’t call me late for dinner.\" Run the code several times and there’s no end to the colorful responses you’ll receive.\n",
    "\n",
    "ChatML's greatest power lies in persisting context from one call to the next. As an example, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Jeff! My name is LISA. How can I assist you today?"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a friendly assistant named LISA.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'My name is Jeff. What\\'s your name?'\n",
    "    }\n",
    "]\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then follow up immediately with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have access to your personal information. How can I assist you today? If you tell me your name, I'll be happy to use it!"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a friendly assistant named LISA.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is my name?'\n",
    "    }\n",
    "]\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM will respond with something along the lines of \"I'm sorry, but I don’t have access to that information.\" But now try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Jeff. How can I assist you today, Jeff?"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a friendly assistant named LISA.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'My name is Jeff. What\\'s your name?'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': 'Hello Jeff, my name is LISA. Nice to meet you!'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is my name?'\n",
    "    }\n",
    "]\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get it? Calls to `GPT-4o` are stateless. If you give `GPT-4o` your name in one call and ask it to repeat your name in the next call, it has no clue. But with ChatML, you can provide past responses as context for the current call. You can build a conversational assistant simply by repeating the last few prompts and responses in each call to `GPT-4o`. The further back you go, the longer the assistant's \"memory\" will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "LLMs don't work with words; they work with *tokens*. Tokenization plays an important role in Natural Language Processing. Neural networks can’t process text, at least not directly; they only process numbers. Tokenization converts words into numbers that a deep-learning model can understand. When `GPT-4o` generates a response by predicting a series of tokens, the tokenization process is reversed to convert the tokens into human-readable text.\n",
    "\n",
    "OpenAI LLMs use a form of tokenization called [Byte-Pair Encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) (BPE), which was developed in the 1990s as a mechanism for compressing text. Today, it is widely used in the NLP space. Here’s how `GPT-4o` BPE-tokenizes the phrase \"fourscore and seven years ago:\"\n",
    "\n",
    "![](Images/bpe.png)\n",
    "\n",
    "As a rule of thumb, 3 words on average translate to about 4 BPE tokens. That’s important because LLMs limit the number of tokens in each API call. The maximum token count is controlled by a parameter named `max_tokens`. For `GPT-4o`, the default is 4,096 tokens or about 3,000 words. `GPT-4o` has a context window size of 128K, so the upper limit is 128K. That's enough to pass in a document that's a few hundred pages long. If the number of tokens generated exceeds `max_tokens`, then either the call will fail or the response will be truncated.\n",
    "\n",
    "You can compute the number of tokens generated from a text sample with help from a Python package named [`tiktoken`](https://pypi.org/project/tiktoken/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 tokens\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    " \n",
    "text = '''\n",
    "    Jeff loves to build and fly model jets. He built his first\n",
    "    jet, a BVM BobCat, in 2007. After that, he built a BVM Bandit,\n",
    "    a Skymaster F-16, and a Skymaster F-5. The latter two are 1/6th\n",
    "    scale models of actual fighter jets. Top speed is around 200 MPH.\n",
    "    '''\n",
    " \n",
    "encoding = tiktoken.encoding_for_model('gpt-4o')\n",
    "num_tokens = len(encoding.encode(text))\n",
    "print(f'{num_tokens} tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can estimate the token count for an entire `messages` array with the following code, which was adapted comments and all from the [OpenAI documentation](https://platform.openai.com/docs/guides/chat/introduction):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 tokens\n"
     ]
    }
   ],
   "source": [
    "num_tokens = 0\n",
    " \n",
    "for message in messages:\n",
    "    num_tokens += 4 # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "    for key, value in message.items():\n",
    "        num_tokens += len(encoding.encode(value))\n",
    "        if key == 'name':  # if there's a name, the role is omitted\n",
    "            num_tokens += -1 # role is always required and always 1 token\n",
    "             \n",
    "num_tokens += 2 # every reply is primed with <im_start>assistant\n",
    "print(f'{num_tokens} tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of reasons to be aware of the token count in each call. First, you’re charged by the token for input and output. The larger the `messages` array and the longer the response, the more you pay. Second, when using the messages array to provide context from previous calls, you have a finite amount of space to work with. It's common practice to pick a number – say, 10 or 20 – and limit the context from previous calls to that number of messages, or to programmatically compute the number of tokens that a conversation comprises and include as many messages as `max_tokens` will allow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language processing\n",
    "\n",
    "`GPT-4o` can perform many NLP tasks such as sentiment analysis and neural machine translation (NMT) without further training. Here's an example that translates text from English to French. It's a good idea to set `temperature` to 0 here since you generally want translations to be accurate and repeatable rather than creative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff adore construire et piloter des maquettes de jets. Il a construit son premier jet, un BVM BobCat, en 2007. Après cela, il a construit un BVM Bandit, un Skymaster F-16 et un Skymaster F-5. Ces deux derniers sont des modèles à l'échelle 1/6 de véritables avions de chasse. La vitesse maximale est d'environ 200 MPH."
     ]
    }
   ],
   "source": [
    "content =  f'Translate the following text from English to French: {text}'\n",
    "\n",
    "messages = [{ 'role': 'user', 'content': content }]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following examples demonstrate how to use `GPT-4o` for sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the review is positive."
     ]
    }
   ],
   "source": [
    "content = '''\n",
    "    Indicate whether the following review's sentiment is positive or\n",
    "    negative: Great food and excellent service.\n",
    "    '''\n",
    "\n",
    "messages = [{ 'role': 'user', 'content': content }]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the review is negative."
     ]
    }
   ],
   "source": [
    "content = '''\n",
    "    Indicate whether the following review's sentiment is positive or\n",
    "    negative: Long lines and poor customer service.\n",
    "    '''\n",
    "\n",
    "messages = [{ 'role': 'user', 'content': content }]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is a text-classification task. LLMs can classify text in other ways, too. The next two examples demonstrate how to use `GPT-4o` as a spam filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the content provided, the email appears to be a legitimate workplace communication regarding a scheduled code review. Therefore, it is not spam."
     ]
    }
   ],
   "source": [
    "content = '''\n",
    "    Indicate whether the following email is spam or not spam:\n",
    "    Please plan to attend the code review at 2:00 p.m. this afternoon.\n",
    "    '''\n",
    "\n",
    "messages = [{ 'role': 'user', 'content': content }]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This email is likely spam. It contains a common trait of spam emails which is the promotion of prescription medications with the promise of saving money. Such emails often come from unverified sources and can be associated with scams or potentially harmful products."
     ]
    }
   ],
   "source": [
    "content = '''\n",
    "    Indicate whether the following email is spam or not spam:\n",
    "    Order prescription meds online and save $$$.\n",
    "    '''\n",
    "\n",
    "messages = [{ 'role': 'user', 'content': content }]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A practical use for LLMs is parsing freeform address fields and generating structured data. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Name\": \"\",\n",
      "    \"Street Address\": \"11 Aviation Avenue\",\n",
      "    \"City\": \"Charlottetown\",\n",
      "    \"State\": \"Prince Edward Island\",\n",
      "    \"Country\": \"Canada\",\n",
      "    \"Postal Code\": \"C1E 0A1\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Roche Molecular Systems, Inc.\",\n",
      "    \"Street Address\": \"4300 Hacienda Drive\",\n",
      "    \"City\": \"Pleasanton\",\n",
      "    \"State\": \"California\",\n",
      "    \"Country\": \"United States\",\n",
      "    \"Postal Code\": \"94588\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Cross Research S.A., Phase I Unit\",\n",
      "    \"Street Address\": \"Via F.A. Giorgioli 14\",\n",
      "    \"City\": \"Arzo\",\n",
      "    \"State\": \"\",\n",
      "    \"Country\": \"Switzerland\",\n",
      "    \"Postal Code\": \"6864\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Wasdell Group, Wasdell Packaging Ltd\",\n",
      "    \"Street Address\": \"Unit 1-8, Euroway Industrial Estate, Blagrove\",\n",
      "    \"City\": \"Swindon\",\n",
      "    \"State\": \"\",\n",
      "    \"Country\": \"United Kingdom\",\n",
      "    \"Postal Code\": \"SN5 8YW\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"\",\n",
      "    \"Street Address\": \"Largo Gemelli 8, 4th Floor, Wing J, Policlinico Gemelli\",\n",
      "    \"City\": \"Rome\",\n",
      "    \"State\": \"\",\n",
      "    \"Country\": \"Italy\",\n",
      "    \"Postal Code\": \"00168\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Academisch Ziekenhuis Maastricht, CDL Stamcellaboratorium\",\n",
      "    \"Street Address\": \"P. Debyelaan 25 5e\",\n",
      "    \"City\": \"Maastricht\",\n",
      "    \"State\": \"\",\n",
      "    \"Country\": \"Netherlands\",\n",
      "    \"Postal Code\": \"6229 HX\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Wintellect Brussels\",\n",
      "    \"Street Address\": \"Leuvensesteenweg 555\",\n",
      "    \"City\": \"Marken Benelux\",\n",
      "    \"State\": \"\",\n",
      "    \"Country\": \"Belgium\",\n",
      "    \"Postal Code\": \"1930\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"SCM department, AstraZeneca K.K., Maihara Factory, AstraZeneca K.K.\",\n",
      "    \"Street Address\": \"215-31 Miyos\",\n",
      "    \"City\": \"\",\n",
      "    \"State\": \"Shiga\",\n",
      "    \"Country\": \"Japan\",\n",
      "    \"Postal Code\": \"215-31\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Healthcare Logistics Australia\",\n",
      "    \"Street Address\": \"7 Dolerite Way\",\n",
      "    \"City\": \"Pemulwuy\",\n",
      "    \"State\": \"New South Wales\",\n",
      "    \"Country\": \"Australia\",\n",
      "    \"Postal Code\": \"2145\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Suncoast Research\",\n",
      "    \"Street Address\": \"2128 W Flagler St, Suite 101\",\n",
      "    \"City\": \"Miami\",\n",
      "    \"State\": \"Florida\",\n",
      "    \"Country\": \"United States\",\n",
      "    \"Postal Code\": \"33135\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "addresses = [\n",
    "    '11 Aviation Avenue, Charlottetown, PE C1E 0A1, Canada',\n",
    "    'Roche Molecular Systems, Inc., 4300 Hacienda Drive, Pleasanton, CA 94588, US',\n",
    "    'Cross Research S.A., Phase I Unit, Via F.A. Giorgioli 14, Arzo, 6864, CH',\n",
    "    'Wasdell Group, Wasdell Packaging Ltd Unit 1-8, Euroway Industrial Estate, Blagrove, Swindon, SN5 8YW, GB',\n",
    "    'Policlinico Gemelli, 4th Floor, Wing J, Largo Gemelli 8, Rome, 00168, IT',\n",
    "    'Academisch Ziekenhuis Maastricht, CDL Stamcellaboratorium, P. Debyelaan 25 5e, Maastricht, 6229 HX, NL',\n",
    "    'Wintellect Brussels, Leuvensesteenweg 555, Marken Benelux, 1930, BE',\n",
    "    'SCM department, AstraZeneca K.K., Maihara Factory, AstraZeneca K.K., 215-31, Miyos, Shiga-Ken, 215-31, JP',\n",
    "    'Healthcare Logistics Australia, 7 Dolerite Way, Pemulwuy NSW 2145, AU',\n",
    "    'Suncoast Research, 2128 W Flagler St, Suite 101, Mami, FL, 33135, US'\n",
    "]\n",
    "\n",
    "for address in addresses:\n",
    "    content = f'''\n",
    "        Parse the freeform address below into fields and return a JSON\n",
    "        representation that uses the following format. Convert country\n",
    "        abbreviations such as \"CA\" into country names such as \"Canada\"\n",
    "        and state abbreviations such as \"CA\" into state names such as\n",
    "        \"California.\" Leave unknown fields blank. Also correct any\n",
    "        obvious misspellings.\n",
    "    \n",
    "        {{\n",
    "            \"Name\": \"Recipient\",\n",
    "            \"Street Address\": \"Street address\",\n",
    "            \"City\": \"City, town, etc.\",\n",
    "            \"State\": \"State, province, region, territory, canton, county, department, länder, or prefecture\",\n",
    "            \"Country\": \"Country name\",\n",
    "            \"Postal Code\": \"Postal code\"\n",
    "        }}\n",
    "    \n",
    "        Address: {address}\n",
    "        '''\n",
    "\n",
    "    messages = [{ 'role': 'user', 'content': content }]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=messages,\n",
    "        response_format={ 'type': 'json_object' },\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    for chunk in response:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        if content is not None:\n",
    "            print(content, end='')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GPT-4o`'s 128K context-window size enables it to ingest large documents for summarization or other purposes. Let's see what it can do with Microsoft's 2022 annual report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Microsoft Annual Report 2022 Summary\n",
       "\n",
       "## Letter from the CEO\n",
       "In 2022, Microsoft navigated a period of significant global challenges including high inflation, supply chain disruptions, and geopolitical tensions, notably the war in Ukraine. Despite this, the company delivered record financial results, with $198 billion in revenue and $83 billion in operating income. Microsoft Cloud passed $100 billion in annualized revenue. The company's mission to empower every individual and organization through technology remains crucial.\n",
       "\n",
       "### Key Customer Stories:\n",
       "- **Ferrovial**: Building safer roads with Microsoft's cloud infrastructure.\n",
       "- **Peace Parks Foundation**: Protecting ecosystems using Dynamics 365, Power BI, Azure AI, and IoT.\n",
       "- **Kawasaki Heavy Industries**: Enhancing productivity and safety using Azure IoT and HoloLens in the industrial metaverse.\n",
       "- **Globo**: Empowering employees with Power Platform for scheduling and set bookings.\n",
       "- **Ørsted**: Using Microsoft's Intelligent Data Platform for predictive maintenance in wind energy production.\n",
       "\n",
       "## Financial Highlights\n",
       "- **Revenue**: $198 billion\n",
       "- **Operating Income**: $83 billion\n",
       "- **Microsoft Cloud Revenue**: Over $100 billion\n",
       "\n",
       "## Commitments and Focus Areas\n",
       "1. **Inclusive Economic Growth**\n",
       "   - Microsoft pledged to equip 10 million underserved individuals with digital skills by 2025.\n",
       "   - The company aims to address the cybersecurity workforce gap with a commitment to train 250,000 people by 2025.\n",
       "   - Provided $3.2 billion in donated and discounted technology to nonprofits in 2022.\n",
       "\n",
       "2. **Fundamental Rights**\n",
       "   - Expanded efforts to provide affordable broadband and address racial injustice.\n",
       "   - Protected 4 million accounts of election officials and human rights organizations through AccountGuard.\n",
       "\n",
       "3. **Sustainability Initiatives**\n",
       "   - Released the second annual sustainability report.\n",
       "   - Committed to becoming carbon negative, water positive, and zero waste.\n",
       "   - Invested in water replenishment projects and diverted significant solid waste from landfills.\n",
       "\n",
       "4. **Trust and Technology**\n",
       "   - Emphasized privacy, security, and responsible AI development.\n",
       "   - Processed 43 trillion security signals daily and blocked billions of threats.\n",
       "\n",
       "## Forward Looking Statements\n",
       "Microsoft remains focused on leveraging technological advancements to drive economic output and address global challenges. The company anticipates continued growth and influence of technology on the global economy, expecting technology's percentage of GDP to double in coming years.\n",
       "\n",
       "### Key Areas of Opportunity:\n",
       "- **Azure and Cloud Services**\n",
       "- **Data and AI Innovations**\n",
       "- **Low-code/No-code tools**\n",
       "- **Business Applications**\n",
       "- **Gaming and Xbox Future**\n",
       "\n",
       "## Culture and Representation\n",
       "Microsoft is dedicated to maintaining a growth mindset culture, emphasizing diversity, inclusion, and giving. In 2022, employees contributed $255 million to over 32,000 nonprofits and volunteered extensively.\n",
       "\n",
       "### Representation Goals:\n",
       "- Increase diversity among senior leaders.\n",
       "- Support a broader ecosystem of suppliers and partners.\n",
       "\n",
       "### Employee Welfare\n",
       "- Enhanced benefits and compensation packages.\n",
       "- Develop learning and development opportunities.\n",
       "- Introduced flexible hybrid work guidelines.\n",
       "\n",
       "## Stock Repurchase and Financial Performance\n",
       "- **Stock Repurchases**: Completed with a remaining $40.7 billion authorization.\n",
       "- **Dividends**: Paid $18.6 billion in 2022.\n",
       "\n",
       "## Future Outlook\n",
       "Microsoft's commitment to sustainability, cybersecurity, and technological innovation positions it to navigate and shape the future through inclusive growth and responsible practices. The upcoming acquisition of Activision Blizzard aims to bolster Microsoft’s gaming segment and foster further innovation.\n",
       "\n",
       "---\n",
       "\n",
       "Satya Nadella\n",
       "Chairman and CEO\n",
       "October 24, 2022"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "with open('Data/annual-report.txt', 'r') as file:\n",
    "    report = file.read()\n",
    "\n",
    "content = f'''\n",
    "    Summarize the following annual report from Microsoft. Use\n",
    "    markdown formatting in your output:\n",
    "\n",
    "    {report}\n",
    "    '''\n",
    "\n",
    "messages = [{ 'role': 'user', 'content': content }]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "output = response.choices[0].message.content\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, let's see how Gemini 1.5 Flash summarizes the same report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Microsoft Fiscal Year 2022 Annual Report Summary\n",
       "\n",
       "This report from Microsoft highlights the company's record-breaking fiscal year 2022, which saw $198 billion in revenue and $83 billion in operating income. The report emphasizes Microsoft's commitment to empowering every person and organization to achieve more through digital technology, while also addressing global challenges.\n",
       "\n",
       "**Key Highlights:**\n",
       "\n",
       "* **Record Revenue and Profit:** Microsoft reported a strong financial performance with record revenue and operating income. The Microsoft Cloud surpassed $100 billion in annualized revenue for the first time.\n",
       "* **Digital Imperative:** The report outlines Microsoft's focus on the \"digital imperative,\" emphasizing the need for every organization to infuse technology into every business process to thrive in a changing economic landscape.\n",
       "* **Sustainability Commitment:** Microsoft re-iterates its commitment to becoming carbon negative, water positive, and zero waste by 2030. It highlights progress on these goals while acknowledging the challenges of achieving net-zero emissions.\n",
       "* **Inclusive Growth:**  Microsoft outlines its efforts to support inclusive economic growth by expanding access to digital skills and technology, particularly for underserved communities.  \n",
       "* **Protecting Fundamental Rights:** The report emphasizes Microsoft's dedication to protecting fundamental rights, including democracy, human rights, and addressing racial injustice and inequity. It highlights initiatives like broadband expansion, increasing representation within the company, and supporting justice reform partnerships.\n",
       "* **Earning Trust:** Microsoft emphasizes the importance of trust in its business model and technology. The report discusses initiatives related to privacy, security, digital safety, and responsible AI development. \n",
       "* **Cultural Focus:** The report emphasizes Microsoft's culture, highlighting the importance of a growth mindset, customer obsession, and diversity & inclusion.  \n",
       "\n",
       "**Microsoft's Opportunity:**\n",
       "\n",
       "The report highlights Microsoft's strategic position in key areas:\n",
       "\n",
       "* **Apps and Infrastructure:**  Expanding Azure as the world's computer, with Azure Arc and Azure for Operators. Leading the industrial metaverse with Azure IoT, Azure Digital Twins, and Microsoft Mesh.\n",
       "* **Data and AI:**  Delivering the most comprehensive data stack with Microsoft Intelligent Data Platform, Cosmos DB, Azure Synapse, and Microsoft Purview.  Leveraging Azure OpenAI Service for advanced coding and language models.\n",
       "* **Digital and App Innovation:**  Providing developers with popular tools across clouds and platforms, including GitHub, GitHub Copilot, Visual Studio, and Azure PaaS services.  Empowering organizations with Power Platform's low-code/no-code solutions.\n",
       "* **Business Applications:**  Helping businesses become hyperconnected with Dynamics 365 Connected Spaces and integrated Dynamics 365 and Teams solutions.  Offering industry clouds to accelerate value, agility, and cost reduction.\n",
       "* **Modern Work:**  Providing the leading platform for work, Microsoft Teams, with over 270 million monthly active users.  Introducing Teams Rooms and Microsoft Viva for enhanced collaboration and employee experience.\n",
       "* **Modern Life:**  Introducing Windows 11 with a redesigned user experience, a new store, and a more open ecosystem for developers and creators. Launching new Surface devices and offering Microsoft 365 consumer subscriptions.\n",
       "* **Security:**  Building security by design into every product.  Providing comprehensive security solutions across clouds and platforms with the Entra product family and Microsoft Security Experts.\n",
       "* **LinkedIn:**  Connecting professionals for increased productivity, job seeking, learning, and marketing. Achieving over $1 billion in annual revenue across various business lines.\n",
       "* **Search, Advertising, and News:**  Creating a new monetization engine for the web, focused on Microsoft Edge, Microsoft Bing, Microsoft Start, and the acquisition of Xandr.\n",
       "* **Gaming:**  Continuing to invest in content, community, and cloud gaming with Xbox Series S/X consoles, Xbox Cloud Gaming, Xbox Game Pass, and the planned acquisition of Activision Blizzard. \n",
       "\n",
       "The report concludes with a strong message about Microsoft's mission, responsibility, and opportunity to make a positive impact on the world.  The company positions itself as a leader in driving positive change through technology.\n",
       "\n",
       "**The report also includes a detailed financial review, covering:**\n",
       "\n",
       "* Share repurchases and dividends\n",
       "* Stock performance\n",
       "* Revenue and operating expense breakdowns by segment\n",
       "* Liquidity and capital resources\n",
       "* Critical accounting estimates\n",
       "* Recent accounting guidance\n",
       "* Quantitative and qualitative disclosures about market risk\n",
       "* Financial statements and supplementary data\n",
       "\n",
       "Overall, the report provides a comprehensive overview of Microsoft's fiscal year 2022 performance, its strategic vision for the future, and its commitment to responsible and impactful technology development. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='GOOGLE_API_KEY')\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(content)\n",
    "output = response.text\n",
    "\n",
    "display(Markdown(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
